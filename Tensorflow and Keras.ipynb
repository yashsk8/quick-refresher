{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e2584a",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45187ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80212167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in tf to run a model, use a session object\n",
    "#eg. \n",
    "# sess = tf.compat.v1.Session()\n",
    "# sess.run(something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tf.compat.v1.placeholder(dtype=tf.float32, shape=(None, input_size), name='inputs') #acts as a placeholder for input data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a tensorflow single layer perceptron\n",
    "#logits-represent real number mappings from probabilities\n",
    "logits = tf.keras.layers.Dense(inputs, output_size, name='logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf metrics\n",
    "#sigmoid-opposite of logits-real number mappings to probabilities\n",
    "probs = tf.math.sigmoid(logits)\n",
    "rounded_probs = tf.math.round(tf.math.sigmoid(logits)) #round to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#math\n",
    "#casting\n",
    "predictions = tf.cast(rounded_probs, dtype = tf.int32) \n",
    "\n",
    "#equal to\n",
    "is_correct = tf.math.equal(predictions, labels)\n",
    "\n",
    "#reduce mean\n",
    "tf.math.reduce_mean(tf.cast(is_correct, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf -- use cross entropy to calculate loss for classification\n",
    "cross_entropy=tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_float, logits=logits)\n",
    "loss=tf.math.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use adam optimizer for reducing loss\n",
    "adam = tf.compat.v1.train.AdamOptimizer()\n",
    "train_op = adam.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d156cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize global varaibles -- this ensure starting logits are zero\n",
    "init_op = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257f2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax for multiclass classification using MLP\n",
    "softmax_t = tf.nn.softmax(t)\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(softmax_t)\n",
    "\n",
    "preds = tf.argmax(probs, axis=-1) # to get the label from the final probabilities of the output model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ead08",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074fcdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model\n",
    "layer1 = Dense(5, activation='relu', input_dim=4)\n",
    "layer2 = Dense(3, activation='relu')\n",
    "layer3 = Dense(3, activation='softmax')\n",
    "model = Sequential([layer1, layer2, layer3])\n",
    "\n",
    "\n",
    "model.compile('adam',\n",
    "              loss='binary_crossentropy', #categorical_crossentropy for multiclass\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "train_output = model.fit(data, labels,\n",
    "                         batch_size=20, epochs=5)\n",
    "\n",
    "#dictionary that contains the metric values at each epoch of training\n",
    "train_output.history\n",
    "\n",
    "#evaluate model\n",
    "model.evaluate(eval_data, eval_labels)\n",
    "\n",
    "#make predictions\n",
    "model.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "projectenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
